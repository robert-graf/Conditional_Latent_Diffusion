model:
  base_learning_rate: 0.000001
  target: ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    linear_start: 0.0015
    linear_end: 0.0195
    num_timesteps_cond: 1
    log_every_t: 500
    timesteps: 1000
    first_stage_key: image
    cond_stage_key: class_label # Produced by the dataset
    image_size: 32 #After downscale (A)
    channels: 4 #After downscale (B without concat; is used to creat the random noise for sampling)
    cond_stage_trainable: true # We do not want the encoder to be trained.
    conditioning_key: crossattn # hybrid,crossattn,concat
    monitor: val/loss
    use_ema: True    
    #scale_factor: 0.18215 defaut = 1 
    
    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 8 #(A) Dependen on first stage
        in_channels: 4 # 8 - concat #(B+concat) Dependen on first stage
        out_channels: 4 #(B)
        model_channels: 192
        attention_resolutions: [ 1, 2, 4, 8 ]
        num_res_blocks: 2
        channel_mult: [ 1,2,2,4,4 ]  # 32, 16, 8, 4, 2
        num_heads: 8
        use_spatial_transformer: true
        transformer_depth: 1
        context_dim: 512
        use_scale_shift_norm: True
        resblock_updown: True

    
    first_stage_config:
      config_path: logs/2024-09-25T12-05-27_autoencoder_kl_32x32x4_gray/autoencoder_kl_32x32x4_gray.yaml
      ckpt_path: logs/2024-09-25T12-05-27_autoencoder_kl_32x32x4_gray/checkpoints/last.ckpt
    
    #cond_stage_config:
    #  config_path: logs/2024-09-25T12-05-27_autoencoder_kl_32x32x4_gray/autoencoder_kl_32x32x4_gray.yaml
    #  ckpt_path: logs/2024-09-25T12-05-27_autoencoder_kl_32x32x4_gray/checkpoints/last.ckpt
    cond_stage_config:
      target: ldm.modules.encoders.modules.ClassEmbedder
      params:
        n_classes: 2
        embed_dim: 512
        key: class_label

data:
  target: main.DataModuleFromConfig
  
  params:
    batch_size: 16
    wrap: True
    num_workers: 16 # Depends on the maschien
    train:
      target: ldm.data.T2w_2_CT.ImageSRTrain
      params:
        size: 256
        image_dropout: 0.1
        vflip: True
        hflip: True
        dflip: True
        rotation: 45
        noise: 0.3
        noise_factor: 0.1
        blur: 0.25
        gauss : 0.25
        random_zoom: True
        zoom_min: 0.8
        zoom_max: 1.2
    validation:
      target: ldm.data.T2w_2_CT.ImageSRValidation
      params:
        size: 256
        image_dropout: 0.0

trainer:
  max_epochs: 10000
